Layered Explanation
üöÄ Layer 1 ‚Äì High level: How I‚Äôd frame it

‚ÄúI‚Äôll treat this in two horizons:
Mid-term (now ‚Üí next few weeks/month): stabilize and scale the existing 3-tier app with minimal code change.
Long-term (next few months+): evolve to a cloud-native, multi-AZ, eventually multi-region architecture with automation, observability, and cost control.‚Äù

Garage today: Web, app, DB all on one box ‚Üí single point of failure, no elasticity.

Mid-term: Lift to cloud, separate tiers, add load balancing, autoscaling, managed database, caching, CDN.

Long-term: Containers / PaaS, microservice or modular architecture, event-driven, global scale, SRE-style operations.

That‚Äôs the executive summary.

üöÄ Layer 2 ‚Äì Medium depth: Concrete mid-term vs long-term moves
Current state: One box in the garage

Single server with:

Presentation (web UI)

Application logic

Database (likely a single relational DB)

Risks:

Single point of failure

Limited CPU/RAM/IO ‚Üí capacity cliff

No monitoring, no autoscale, no proper backup

Mid-term strategy (to survive 1,000 ‚Üí 100,000 users)

Guiding principle: Change as little as possible in the code, but upgrade the platform and topology.

1. Lift to cloud and separate tiers

Azure:

Move web/app to Azure App Service or VM Scale Set.

Move DB to Azure SQL Database or Azure Database for MySQL/Postgres.

AWS equivalent: EC2/Auto Scaling + ALB, RDS.

GCP equivalent: GCE/Managed Instance Group + Cloud SQL.

2. Introduce load balancing and horizontal scaling of the web/app tier

Place a Layer-7 load balancer in front:

Azure Application Gateway / Azure Front Door

(AWS ALB / GCP HTTP(S) LB)

Make app tier stateless (sessions in Redis/DB) so you can:

Scale out instances based on CPU/requests.

Deploy without sticky sessions.

3. Offload static content and use CDN

Move images, CSS/JS, product photos to object storage:

Azure Blob Storage (+ Azure CDN / Front Door)

(AWS S3 + CloudFront / GCP Cloud Storage + Cloud CDN)

This reduces load on your origin servers dramatically for 100k users.

4. Strengthen the database layer without full redesign

Move to managed relational DB:

Azure SQL with Elastic Pools or Hyperscale if needed.

Enable:

Read replicas (where available) for read-heavy workloads.

Proper backup/restore, PITR (Point-in-Time Recovery).

Add application-level caching (Azure Cache for Redis) to reduce DB reads.

5. Basic resilience, security, and observability

Resilience: Multi-AZ / zone-redundant deployment.

Security:

WAF in front (Azure WAF)

Managed identity, RBAC, secrets in Key Vault.

Observability:

Central logs + metrics with Azure Monitor / Application Insights.

Alerts on latency, error rates, CPU, DB connections.

This mid-term posture will comfortably handle thousands to low hundreds of thousands of users if sized correctly and autoscale is tuned.

üöÄ üöÄ  Long-term strategy (to sustain 4M+ users in 3 months and beyond)

Here we move from ‚Äúscaled monolith‚Äù ‚Üí ‚Äúcloud-native platform‚Äù.

1. Containerization and platform standardization

Package the app into containers.

Run on:

Azure Kubernetes Service (AKS), or

Azure Container Apps for simpler PaaS.

Benefits:

Predictable deployment unit

Fine-grained scaling per component

Easier canary/blue-green deployments

(AWS: EKS/ECS/Fargate; GCP: GKE/Cloud Run).

2. Modularize / microservices where it adds value

Split into logical domains over time, e.g.:

Product catalog service

Checkout / order service

Payment service

Inventory service

User / identity service

This unlocks:

Independent scaling ‚Äî e.g., checkout can scale faster than admin panel.

Independent deployment cadence.

Fault isolation ‚Äî payment issues don‚Äôt take down browsing.

3. Evolve data architecture

Move towards polyglot persistence:

Relational DB (Azure SQL) for core transactional data.

NoSQL (Cosmos DB) for high-volume, flexible catalog or sessions.

Search engine (Azure AI Search / Elastic) for product search.

Consider:

CQRS pattern (separate read and write models).

Sharding or partitioning strategy for large tables (orders, events).

Use event-driven architecture:

Azure Event Hubs / Service Bus for order events, inventory changes, notifications.

4. Global scale, performance, and reliability

Multi-region deployment:

Active-active for read (catalog, browse), maybe active-passive for write (orders).

Use Azure Traffic Manager / Front Door for global routing.

Hard SLOs:

p99 latency targets

Availability targets (e.g., 99.9 or 99.99)

DR strategy:

Defined RPO/RTO

Cross-region DB replication, tested failover runbooks.

5. CloudOps, automation, and governance (Azure focus)

Infrastructure as Code:

Bicep / Terraform for all infra (AKS, networking, DB, Azure Front Door, Redis).

CI/CD pipelines:

Azure DevOps / GitHub Actions:

Build ‚Üí test ‚Üí security scan ‚Üí deploy (blue/green / canary).

Cost & performance optimization:

Autoscale rules based on business KPIs (requests, queue depth, revenue per minute), not just CPU.

Right-size SKUs, use reserved instances or savings plans where usage is stable.

Use Azure Advisor and Cost Management for continuous cost tuning.

Security & compliance:

Centralized identity with Entra ID, conditional access.

Network segmentation (Hub-Spoke, NSGs, Private Endpoints).

Continuous posture management with Defender for Cloud.

That long-term design is how you support millions of users, handle marketing spikes, and still keep cost, resilience, and security under control.

3. Analogy ‚Äì From garage food stall to global restaurant chain

Right now, your app is like a single tiny food stall in your garage:

You cook, serve, do billing, and clean ‚Äî all from one counter.

Mid-term: You move to a proper restaurant:

Separate kitchen, serving area, billing counter.

You hire a couple of staff, add more stoves, and use a delivery partner.

Long-term: You build a franchise chain:

Standardized kitchens, regional warehouses, central billing system, training, quality checks, and a supply chain.

Each outlet can be opened, scaled, or shut down without collapsing the brand.

Cloud-wise:

Garage server ‚Üí One food stall

Lift-and-shift + load balancer + managed DB ‚Üí First proper restaurant

Containers, microservices, multi-region, CI/CD ‚Üí Global franchise chain

Bonus: Likely follow-up questions & anchor answers (you can reuse live)

You can expect the panel to drill down. Here are strong one-liner hooks:

‚ÄúWhy not just keep scaling the single server vertically?‚Äù

Vertical scaling hits hardware ceilings, keeps a single point of failure, and gets cost-inefficient; horizontal scaling with stateless services and managed data stores is the only sustainable path for millions of users.

‚ÄúHow do you stop the database becoming the bottleneck?‚Äù

I‚Äôd combine read replicas, aggressive caching (Redis), proper indexing, and ‚Äî long-term ‚Äî CQRS and partitioning/sharding or polyglot persistence for high-volume domains.

‚ÄúHow do you migrate without downtime?‚Äù

Blue-green or canary deployments behind a load balancer, plus DB migration scripts with backward-compatible schema changes and controlled traffic shifting.

‚ÄúHow do you manage cost at 4M users?‚Äù

Autoscaling on business metrics, right-sizing SKUs, offloading to serverless for spiky workloads, and using cost governance (budgets, tags, FinOps reviews) as a first-class discipline.

----------------------------------------------

Full Narrative You Can Say in an Interview (Business-friendly)

‚ÄúLet me explain it in the simplest way possible.

You started with a small shoe website running on one computer in your garage. That works fine when 10 or 20 customers visit.

When you suddenly get 1,000 customers next week

I‚Äôd first ask:
‚ÄòDo you have a bigger machine in your garage?‚Äô
If yes ‚Äî we use it immediately.
If not ‚Äî we move your website to a cloud provider where we can instantly rent a bigger machine.

When you reach 100,000 customers the next month

Your garage can‚Äôt handle this anymore.
So we split your system into three parts ‚Äî
a storefront, business logic, and database ‚Äî
so each part can grow at its own pace.

We also add:
‚Ä¢ a traffic director at the front door
‚Ä¢ faster delivery of your images
‚Ä¢ a backup system
‚Ä¢ and a small warehouse of frequently used items (cache)

This stabilizes your business.

When you hit 4 million customers in three months

This is not a garage story anymore ‚Äî it‚Äôs a franchise story.

We redesign your platform to behave like Starbucks or McDonalds:
‚Ä¢ many locations
‚Ä¢ automatic staffing
‚Ä¢ consistent service
‚Ä¢ instant recovery
‚Ä¢ global monitoring
‚Ä¢ and a supply chain that never breaks

That‚Äôs the long-term architecture.‚Äù

--------------------------------------------------

Follow- up: (non-technical)
1. ‚ÄúHow do you move my website to the cloud where I can rent a bigger machine instantly?‚Äù

Imagine your garage computer is like a small shop.
When customers increase, the shop becomes too tight.

Cloud is basically a giant shopping mall that rents shops on demand.

To move your website:

We pack your website files (your shop items).

We upload them to the cloud provider (the shopping mall).

We choose a shop size depending on your traffic (small, medium, large).

If more customers come, we just upgrade to a bigger shop instantly.

No need to buy anything. You just rent whatever size you need.

2. ‚ÄúHow do you deliver images faster?‚Äù

When customers visit your site, they load pictures of your shoes.
If all those images sit on one computer, the computer gets overloaded.

So we put your shoe photos on a global photo-delivery network.

This is like:

You keep copies of your shoe pictures in many mini-photo stands around the world.
Customers automatically take photos from the stand closest to them.

This makes images load super fast, no matter where they live.

(Technically, this is a CDN ‚Äî but you don‚Äôt need to mention that.)

3. ‚ÄúWhat is a backup system?‚Äù

A backup system is your safety locker.

Imagine your garage burns down.
If all your customer orders and payment history were stored only in that one room, you‚Äôd lose the entire business.

So we:

Copy your important data

Store it in a safe, separate place

Update it regularly

If the main system fails, we simply restore from the copy.

It‚Äôs like having a duplicate key to your shop stored in a bank locker.

4. ‚ÄúHow do you implement a small warehouse of frequently used items (cache)?‚Äù

Think of cache like:

A small shelf in front of your shop where you keep your top-selling shoes.

People buy those every day, so you keep them close and ready.

Technically:

Instead of asking the main database every time,
we keep the most popular information in a quick-access spot.

Customers get responses faster.

The main system doesn‚Äôt get overloaded.

It‚Äôs a speed booster + pressure reducer in one.

5. ‚ÄúWhat do you mean by many locations?‚Äù

Right now, your website lives in one place ‚Äî your garage.

If that garage loses power, your business stops.

When we say ‚Äúmany locations,‚Äù we mean:

Your website runs in multiple buildings across different cities or countries.
If one location fails, another automatically continues serving your customers.

It gives you:

Better performance

Better reliability

Zero downtime during disasters

It‚Äôs like having multiple store branches.

6. ‚ÄúWhat is automatic staffing?‚Äù

This is a great business analogy moment.

Automatic staffing = adding or removing employees based on crowd size.

If 100 people walk into your shop, extra staff automatically appear.
If only 3 customers come in, the extra staff go home.

In cloud terms, your system automatically adds or removes computing power based on traffic.

No manual work.

7. ‚ÄúWhat is consistent service?‚Äù

Consistent service means:

Every customer, anywhere in the world, gets the same smooth experience ‚Äî fast website, instant checkout, no errors.

No surprises. No delays. No slow pages.

Just reliability.

8. ‚ÄúWhat is instant recovery?‚Äù

Instant recovery means:

If something breaks, a backup system takes over instantly ‚Äî before customers even notice.

It‚Äôs like:

If one cashier fainted, the backup cashier already sits in the chair before the queue forms.

This prevents downtime.

9. ‚ÄúWhat do you mean by global monitoring?‚Äù

Global monitoring = a command center.

Imagine a large screen showing:

how many customers are on your website

which pages are slow

which orders failed

whether any location is down

real-time sales

real-time inventory

You see everything happening across all your digital stores.

You can act before customers complain.

10. ‚ÄúWhat is a supply chain that never breaks?‚Äù

This is about the entire system working end-to-end without hiccups:

Customers browse

Add items

Pay

Get order confirmation

Warehouse receives request

Delivery partner is triggered

Everything works without any ‚Äújam‚Äù in the process.

In cloud terms:

Every component is prepared for peak load, backed up, and has multiple support systems.

It‚Äôs like running a global footwear brand where stock NEVER runs out, and orders NEVER get stuck.


------------------------(Technical) ---------------------------------

1. ‚ÄúHow do we move the website to a cloud provider where we can instantly rent a bigger machine?‚Äù

In technical terms:

We lift and shift the existing 3-tier application to cloud compute services so we can scale elastically.

Steps (Cloud-Agnostic Enterprise Approach)

Containerize or VM-ize the existing app
Package the application into a VM image or Docker container.

Provision compute in the cloud

AWS: EC2 / Auto Scaling Group (ASG)

Azure: VM Scale Sets / App Service

GCP: Managed Instance Groups (MIG)

Attach a load balancer to distribute traffic

AWS ALB, Azure Application Gateway, GCP HTTPS LB.

Migrate the database

AWS ‚Üí RDS

Azure ‚Üí Azure SQL / MySQL/Postgres

GCP ‚Üí Cloud SQL

DNS cutover
Point the domain to cloud front-end load balancer.

Why this solves the problem

Cloud compute gives you elasticity ‚Äî machines can scale up or out instantly based on traffic, without purchasing hardware.

2. ‚ÄúHow do you deliver images faster?‚Äù

We use a Content Delivery Network (CDN).

Approach

Store static content (images, CSS, JS) in object storage:

AWS S3

Azure Blob

GCP Cloud Storage

Attach a CDN layer:

AWS CloudFront

Azure Front Door / Azure CDN

GCP Cloud CDN

Enable caching, compression, cache invalidation policies.

Result

Images load from an edge location near the user.

Reduces latency, offloads compute, improves page speed and SEO.

This is essential when scaling from 100k ‚Üí millions of users.

3. ‚ÄúWhat is a backup system?‚Äù

A backup system is a multi-layered data protection strategy.

Cloud Implementation

Automated database backups

RDS automated backups

Azure SQL PITR backups

Cloud SQL automated backups

Geo-redundant storage (GRS/CRR)
Data is replicated across regions.

Snapshot strategy
VM snapshots, DB snapshots, object versioning.

Disaster Recovery (DR) plan
Cross-region failover, RTO/RPO definitions, runbooks.

Outcome

If the primary system fails, we can restore quickly from backups or fail to a secondary region.

4. ‚ÄúHow to implement a small warehouse of frequently used items (cache)?‚Äù

We add a caching layer at multiple points in the architecture.

Caching Strategy

Application-level cache

AWS ElastiCache (Redis)

Azure Cache for Redis

GCP Memorystore

CDN caching
Static resources cached at edge.

Database query result caching

Session caching
Important for stateless app tiers.

Purpose

Reduce load on the DB

Lower request latency

Increase throughput

Improve application responsiveness

This is mandatory when handling more than 100k+ requests per minute.

5. ‚ÄúWhat are many locations?‚Äù

This refers to multi-AZ and multi-region architecture.

Implementation

Multi-Zone (High availability)

Deploy workloads across 2‚Äì3 availability zones

Load balancer spans across AZs

Multi-Region (Disaster Recovery / Global scale)

Active-active (eventual consistency) for read-heavy workloads

Active-passive for strong consistency workloads

Global Traffic Routing

AWS Route53 latency-based routing

Azure Front Door

GCP Cloud Load Balancing

Why it matters

It eliminates single points of failure.
If one region goes down, traffic automatically shifts to another.

6. ‚ÄúWhat is automatic staffing?‚Äù (Autoscaling)

Automatic staffing = Autoscaling.

How it works

App tier becomes stateless.

Add autoscaling policies:

CPU utilization

Requests per second

Queue depth

Custom business metrics (orders/min)

Services:

AWS: Auto Scaling Groups / ECS Fargate / Lambda

Azure: VMSS / AKS autoscaler / Functions

GCP: MIG / Cloud Run / GKE autoscaler

Outcome

The system automatically adds compute nodes during peak traffic and scales down during idle periods.

7. ‚ÄúWhat is consistent service?‚Äù

This refers to reliability and performance consistency across regions, devices, and traffic volumes.

Achieved Through

CI/CD with blue-green or canary deployments

API versioning

Standardized microservice patterns

Containerized workloads

SLO-driven observability

Auto-healing mechanisms

Result

Every user gets the same fast, stable experience, even during massive traffic.

8. ‚ÄúWhat is instant recovery?‚Äù

Instant recovery = self-healing + failover automation.

Components

Health probes (Liveness/Readiness)

Auto-restart of unhealthy nodes

Multi-AZ failover

Automated DB failover

RDS Multi-AZ

Azure SQL Zone-redundant

Cloud SQL HA

Disaster Recovery failover runbooks
orchestrated by cloud-native services.

Outcome

If any node, VM, container, or region fails, the system restores itself without human intervention.

9. ‚ÄúWhat is global monitoring?‚Äù

Global monitoring is a centralized observability system.

Platforms

AWS CloudWatch + X-Ray + CloudTrail

Azure Monitor + Application Insights + Log Analytics

Google Cloud Operations Suite (Stackdriver)

Monitored KPIs

Latency (p95/p99)

Error rates

Server health

Database connections

Queue depth

Cost anomalies

Regional performance

Outcome

You get a real-time operational view of your entire global footprint.

10. ‚ÄúWhat is a supply chain that never breaks?‚Äù

Technically, this refers to resilient, event-driven, decoupled architecture.

How it‚Äôs implemented

Event buses / messaging queues

AWS SNS + SQS

Azure Service Bus / Event Grid

GCP Pub/Sub

Decoupled microservices

Order service

Inventory service

Payment service

Notification service

Idempotent and retry-safe operations

Distributed transaction patterns

Saga Pattern

Outbox Pattern

Observability + tracing across the entire workflow.

Result

Even under peak traffic or partial failures,
orders, payments, inventory sync, and notifications continue flowing.

This is the enterprise backbone for scaling to millions of global users.


--------------------- My Doubts -------------------------

1. DNS cutover ‚Äì point the domain to the cloud front-end load balancer

What it is:
DNS cutover = updating your domain‚Äôs DNS records so traffic stops going to the old server and starts flowing to the cloud load balancer.

How you do it (Azure-focused but cloud-agnostic):

Your domain (e.g., www.shoestore.com) is managed at a registrar or DNS provider.

You create:

Public load balancer / Front Door / App Gateway in Azure with a public endpoint.

In DNS:

Point a CNAME (www) to the load balancer‚Äôs DNS name (e.g., shoestore.azurefd.net), or

Point an A record to its public IP.

Tune TTL (e.g., lower it to 60‚Äì300 seconds before cutover) so switch happens quickly and rollback is easier.

2. Enable caching, compression, cache invalidation policies

Caching

At CDN / Front Door: enable caching for static assets (images, CSS, JS, API responses where appropriate).

Use Cache-Control headers from the app (max-age, s-maxage, no-cache, ETag) to control behavior.

Compression

Enable HTTP compression (Gzip/Brotli) on:

App Gateway / Front Door / web server / App Service.

This reduces payload size ‚Üí lower bandwidth ‚Üí better latency.

Cache invalidation

When you deploy new static assets, you:

Change file names with hashes (app.1234.js), or

Trigger CDN purge/invalidation API on specific paths.

This ensures users don‚Äôt see stale content after releases.

3. Azure SQL ‚Äì Elastic Pools vs Hyperscale

Azure SQL Elastic Pools

Optimized for many small/medium databases with variable usage.

You provision a shared pool of compute (DTUs/vCores) and many DBs consume from that pool.

Use case: SaaS with 100s of tenant DBs; cost-optimized multi-tenant pattern.

Azure SQL Hyperscale

Optimized for very large single databases (up to ~100 TB).

Architecture: decoupled compute and storage with multiple page servers, log service, and snapshot-based storage.

Benefits: rapid scale-out, fast backup/restore (because it's snapshot-based), and high-throughput workloads.

Elevator pitch:

Elastic Pool = many DBs sharing a budget.

Hyperscale = one big beast DB that needs extreme scale and speed.

4. Read replicas for read-heavy workloads

Concept:
Offload read traffic to read-only replicas so the primary focuses on writes.

Implementation (varies by engine):

Azure SQL:

For Hyperscale / Business Critical tiers: enable read scale-out to read-only replicas via a read-only listener.

App routes analytics / non-critical queries to this read endpoint.

Azure Database for MySQL/Postgres:

Create read replicas, configure connection strings for read-heavy services.

App-level:

Implement a read/write routing strategy:

Writes go to primary.

Reports, product search, etc. go to replica.

You emphasize replication lag, consistency expectations, and which workloads are safe on replicas.

5. Proper backup/restore & PITR (Point-in-Time Recovery)

Backup strategy in Azure SQL:

Automatic backups:

Azure SQL keeps full, differential, and transaction log backups in the background.

You configure retention (e.g., 7‚Äì35 days, or up to years with long-term retention).

PITR (Point-in-Time Recovery):

You can restore the DB to any time point within retention window.

Restore operation creates a new database instance at that selected timestamp.

VM / other DBs:

Use snapshot backups or database-native tools (pg_dump, mysqldump, backup agents).

Interview angle:
‚ÄúI design RPO/RTO, confirm retention requirements with the business, then enforce PITR via automated backups and DR runbooks. Restores are tested, not assumed.‚Äù

6. Azure: zone, region, GRS, ZRS, etc.

Region

A geographic location (e.g., East US, West Europe) containing one or more physical datacenters.

Availability Zone (AZ)

A physically separate datacenter within a region with independent power, cooling, and networking.

Zone-aware services can deploy across zone 1, 2, 3 for high availability.

Replication options (Storage resiliency):

LRS (Locally Redundant Storage)

3 copies in one datacenter (one zone).

ZRS (Zone-Redundant Storage)

Data replicated across 3 AZs in the same region.

GRS (Geo-Redundant Storage)

LRS in primary region + asynchronous replication to a secondary region.

GZRS (Geo-Zone-Redundant Storage)

ZRS in primary region + replication to secondary region.

Interview framing:
‚ÄúZones protect against datacenter failures; GRS/GZRS protects against regional disasters.‚Äù

7. Managed Identity and RBAC in Azure

Managed Identity

A first-class identity managed by Azure AD (Entra ID) that is assigned to a resource (VM, App Service, Function, AKS, etc.).

The resource can request OAuth tokens for other Azure services without storing secrets.

How to implement:

Enable System-assigned managed identity on App Service/VM/Function (or user-assigned identity).

In the target resource (e.g., Key Vault, Storage, SQL), assign RBAC roles to that identity:

e.g., Key Vault Secrets User, Storage Blob Data Contributor, etc.

In code:

Use DefaultAzureCredential (Azure SDK) to fetch tokens automatically.

No connection strings or secrets in config.

RBAC (Role-Based Access Control):

Grant permissions based on role + scope:

Role: what you can do (read, write, contributor, owner).

Scope: where you can do it (subscription / resource group / resource).

Principle: least privilege.

8. Canary / blue-green deployments

Blue-Green Deployment

Two identical environments: Blue (current prod) and Green (new version).

Steps:

Deploy new version to Green.

Run tests.

Switch traffic at load balancer / DNS from Blue ‚Üí Green.

Keep Blue as rollback.

Canary Deployment

Gradual rollout:

Deploy new version to a small subset of instances/users (e.g., 1‚Äì5%).

Monitor metrics (errors, latency, business KPIs).

If healthy, increase traffic gradually to 25%, 50%, 100%.

In Azure:

App Service deployment slots.

AKS with service mesh / Ingress + weighted routing.

Front Door / Traffic Manager for percentage-based routing.

Interview hook:
‚ÄúI use blue-green for fast, low-risk environment flips; canary when I want progressive exposure and fine-grained rollback.‚Äù

9. CQRS (Command Query Responsibility Segregation)

Concept:
Separate write operations (commands) from read operations (queries) into different models and often different services.

Why:

Writes often need strict consistency and complex validation.

Reads need denormalized, optimized models for fast queries.

Implementation pattern:

Command side (write model):

Handles create/update/delete.

Often uses normalized relational schema.

May emit events after changes (Event Sourcing pattern).

Query side (read model):

Consumes events, builds read-optimized views (e.g., in NoSQL, search index, cache).

Serves high-volume, low-latency read traffic.

Example:
Orders:

Writes go into a transactional DB.

Reads go from a denormalized view in Cosmos DB / Elastic / Redis.

10. Hard SLOs: p99 latency, availability 99.9 / 99.99

SLO (Service Level Objective)

A target for reliability and performance.

p99 latency target:

p99 = 99th percentile latency.

If p99 = 300 ms, it means 99% of requests complete in ‚â§ 300 ms.

You design capacity, caching, and code paths to meet that.

Availability targets:

99.9% (~43.8 min/month downtime)

99.99% (~4.4 min/month downtime)

You use:

Multi-AZ / multi-region setup

Health checks + auto-heal

Graceful degradation

Rate limiting

Interview framing:
‚ÄúI negotiate SLOs with the business, derive error budgets, and use them to drive capacity planning, release velocity, and incident response.‚Äù

11. Polyglot persistence

Definition:
Use multiple types of data stores in the same system, each chosen for what it does best, rather than forcing everything into one database.

Examples in an e-commerce platform:

Relational DB (Azure SQL) for orders, payments, transactions.

NoSQL (Cosmos DB) for user profiles, carts, catalogs, high-scale reads.

Search engine (Azure AI Search / Elastic) for full-text search and filtering.

Blob Storage for images and documents.

Time-series DB / Log Analytics for telemetry.

Why it matters:

Optimizes for performance, scalability, and developer velocity.

Aligns data stores with access patterns instead of overloading a single RDBMS.

-------------------------------------------------